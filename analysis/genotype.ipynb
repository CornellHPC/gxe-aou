{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b08f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import perf_counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as spl\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.array as da\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from pandas_plink import read_plink, read_plink1_bin, write_plink1_bin\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "os.environ[\"DISABLE_PANDERA_IMPORT_WARNING\"] = \"True\"\n",
    "plt.rcParams['figure.dpi'] = 800\n",
    "plt.rcParams['savefig.dpi'] = 800\n",
    "fig_root = Path('figs/aou/genotype')\n",
    "\n",
    "genome_dir = Path(\"genomic_files/genome\")\n",
    "rsvd_dir = genome_dir / \"rsvd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a679d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(f\"gsutil cp '{my_bucket}/genomic_data/genomic_files.zip' .\")\n",
    "# shutil.unpack_archive(\"genomic_files.zip\", \"genomic_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caaa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bim.snp: SNP IDs (columns)\n",
    "# fam.iid: sample IDs (indices)\n",
    "# bed: raw data\n",
    "bim_full, fam_full, bed_full = read_plink(str(genome_dir / \"qc_data_unrelated\"))\n",
    "bed_full = bed_full.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cadacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bed_full.shape == (len(fam_full), len(bim_full))\n",
    "bed_full # n_subject, n_snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86192024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BedOperator(sp.sparse.linalg.LinearOperator):\n",
    "    def __init__(self, bed, mask, env, covariates, manifest):\n",
    "        if manifest:\n",
    "            self.A = np.ascontiguousarray(bed[mask].compute().astype(np.float32))\n",
    "            self.AT = self.A.T\n",
    "        else:\n",
    "            self.A = bed[mask].rechunk(('auto', -1))\n",
    "            self.AT = bed[mask].T.rechunk(('auto', -1))\n",
    "        \n",
    "        self.env = env\n",
    "        self.Q = None\n",
    "        if covariates is not None:\n",
    "            if covariates.ndim == 1:\n",
    "                covariates = covariates[:, np.newaxis]\n",
    "            self.Q, _ = np.linalg.qr(covariates)\n",
    "            \n",
    "        super().__init__(dtype=np.float32, shape=self.A.shape)\n",
    "        \n",
    "    def _matmat(self, X):\n",
    "        ans = self.env[:, np.newaxis] * (self.A @ X)\n",
    "        if self.Q is not None:\n",
    "            ans = ans - self.Q @ (self.Q.T @ ans)\n",
    "        return ans\n",
    "    \n",
    "    def _rmatmat(self, X):\n",
    "        if self.Q is not None:\n",
    "            X = X - self.Q @ (self.Q.T @ X)\n",
    "        ans = self.AT @ (self.env[:, np.newaxis] * X)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(bed, mask, env, covariates, manifest):\n",
    "    col_modes_path = genome_dir / f\"col_modes.npy\"\n",
    "    if not col_modes_path.is_file():\n",
    "        print(\"Computing column modes...\")\n",
    "        col_modes = da.map_blocks(\n",
    "            lambda x: sp.stats.mode(x, axis=0, nan_policy='omit', keepdims=True)[0], \n",
    "            bed, dtype=bed.dtype, drop_axis=0, new_axis=0\n",
    "        ).compute()\n",
    "        np.save(col_modes_path, col_modes)\n",
    "        print(f\"Cached to {col_modes_path}\")\n",
    "    col_modes = np.load(col_modes_path)\n",
    "    \n",
    "    imputed_base = genome_dir / f\"qc_data_unrelated_imputed\"\n",
    "    if not imputed_base.with_suffix(\".bed\").is_file():\n",
    "        print(\"Computing imputed data...\")\n",
    "        genotype = read_plink1_bin(str(genome_dir / \"qc_data_unrelated.bed\"), verbose=False)\n",
    "        genotype_imputed = genotype.fillna(col_modes)\n",
    "        write_plink1_bin(genotype_imputed, f\"{imputed_base}.bed\", verbose=True)\n",
    "        print(f\"Cached to {imputed_base}.*\")\n",
    "    bim_imp, fam_imp, bed_imputed = read_plink(str(imputed_base))\n",
    "    bed_imputed = bed_imputed.T\n",
    "    \n",
    "    row_sq_sums_path = genome_dir / f\"row_sq_sums.npy\"\n",
    "    if not row_sq_sums_path.is_file():\n",
    "        print(\"Computing row squared sums...\")\n",
    "        row_sq_sums = (bed_imputed**2).sum(axis=-1).compute()\n",
    "        np.save(row_sq_sums_path, row_sq_sums)\n",
    "        print(f\"Cached to {row_sq_sums_path}\")\n",
    "    row_sq_sums = np.load(row_sq_sums_path)\n",
    "    \n",
    "    bed_op = BedOperator(bed_imputed, mask, env, covariates, manifest)\n",
    "    frobenius_sq = np.sum(env**2 * row_sq_sums[mask])\n",
    "    \n",
    "    return bed_op, frobenius_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_rsvd(A, k, n_oversamples=10, n_iter=2, random_state=42, verbose=False):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    m, n = A.shape\n",
    "    l = k + n_oversamples\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"--- Starting Manual RSVD (k={k}, oversamples={n_oversamples}, iter={n_iter}) ---\")\n",
    "    \n",
    "    t_start = perf_counter()\n",
    "\n",
    "    # 1. Generate Omega and Initial Projection\n",
    "    t0 = perf_counter()\n",
    "    Omega = rng.standard_normal(size=(n, l)).astype(np.float32)\n",
    "    Y = A @ Omega\n",
    "    if verbose:\n",
    "        print(f\"[Step 1-2] Init Projection Y = A @ Omega: {perf_counter() - t0:.4f}s\")\n",
    "\n",
    "    # 2. Power Iterations\n",
    "    for i in range(n_iter):\n",
    "        t_iter = perf_counter()\n",
    "        Y, _ = spl.qr(Y, mode='economic')\n",
    "        Y_tilde = A.T @ Y\n",
    "        Y = A @ Y_tilde\n",
    "        if verbose:\n",
    "            print(f\"  > Power Iteration {i+1}/{n_iter}: {perf_counter() - t_iter:.4f}s\")\n",
    "\n",
    "    # 3. QR Decomposition\n",
    "    t0 = perf_counter()\n",
    "    Q, _ = spl.qr(Y, mode='economic')\n",
    "    if verbose:\n",
    "        print(f\"[Step 4] Final QR: {perf_counter() - t0:.4f}s\")\n",
    "\n",
    "    # 4. Form Small Matrix B\n",
    "    t0 = perf_counter()\n",
    "    B = (A.T @ Q).T\n",
    "    if verbose:\n",
    "        print(f\"[Step 5] Form B (Q.T @ A): {perf_counter() - t0:.4f}s\")\n",
    "\n",
    "    # 5. SVD of B\n",
    "    t0 = perf_counter()\n",
    "    U_tilde, S, Vt = spl.svd(B, full_matrices=False)\n",
    "    if verbose:\n",
    "        print(f\"[Step 6] SVD of B: {perf_counter() - t0:.4f}s\")\n",
    "\n",
    "    # 6. Final Projection\n",
    "    U = Q @ U_tilde\n",
    "\n",
    "    # 7. Truncate\n",
    "    U = U[:, :k]\n",
    "    S = S[:k]\n",
    "    Vt = Vt[:k, :]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"--- RSVD Finished in {perf_counter() - t_start:.4f}s ---\")\n",
    "    \n",
    "    return U, S, Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20255f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsvd(bed_op, frobenius_sq, n_component_rsvd, cache_key):\n",
    "    rsvd_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    U_path = rsvd_dir / f\"U_{cache_key}_{n_component_rsvd}.npy\"\n",
    "    S_path = rsvd_dir / f\"S_{cache_key}_{n_component_rsvd}.npy\"\n",
    "    Vt_path = rsvd_dir / f\"Vt_{cache_key}_{n_component_rsvd}.npy\"\n",
    "\n",
    "    if not (U_path.is_file() and S_path.is_file() and Vt_path.is_file()):\n",
    "        print(f\"Running RSVD with {n_component_rsvd} components...\")\n",
    "        U, S, Vt = manual_rsvd(bed_op, k=n_component_rsvd)\n",
    "        np.save(U_path, U)\n",
    "        np.save(S_path, S)\n",
    "        np.save(Vt_path, Vt)\n",
    "        print(f\"Cached to {U_path}, {S_path}, {Vt_path}\")\n",
    "    U, S, Vt = np.load(U_path), np.load(S_path), np.load(Vt_path)\n",
    "    \n",
    "    projections = compute_proj(bed_op, Vt, n_component_rsvd, cache_key)\n",
    "    \n",
    "    visualize_rsvd(S, frobenius_sq, cache_key)\n",
    "    visualize_rsvd(S, frobenius_sq, cache_key, top_k=15)\n",
    "    visualize_rsvd(S, frobenius_sq, cache_key, top_k=20)\n",
    "    visualize_rsvd(S, frobenius_sq, cache_key, top_k=32)\n",
    "    visualize_rsvd(S, frobenius_sq, cache_key, top_k=50)\n",
    "    \n",
    "    return U, S, Vt, projections\n",
    "\n",
    "\n",
    "def compute_proj(bed_op, Vt, n_component_rsvd, cache_key):\n",
    "    proj_path = rsvd_dir / f\"proj_{cache_key}_{n_component_rsvd}.npy\"\n",
    "    if not proj_path.is_file():\n",
    "        print(\"Running projections...\")\n",
    "        projections = bed_op @ Vt.T\n",
    "        np.save(proj_path, projections)\n",
    "        print(f\"Cached to {proj_path}\")\n",
    "    projections = np.load(proj_path)\n",
    "    \n",
    "    return projections\n",
    "\n",
    "\n",
    "def visualize_rsvd(S, frobenius_sq, cache_key, top_n = 40, top_k = None):\n",
    "    x = np.arange(len(S)) + 1\n",
    "    y = 100 * S[:]**2 / np.sum(S[:top_n]**2)\n",
    "    title = f\"Relative Pct. Var. Explained (w.r.t. Top {top_n} PCs)\"\n",
    "    stem = f\"{cache_key}_svdvals\"\n",
    "    if top_k is not None:\n",
    "        x = x[:top_k]\n",
    "        y = y[:top_k]\n",
    "        stem = f\"{cache_key}_svdvals_top{top_k}\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(x, y)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_xlim(left=0.1, right=np.max(x))\n",
    "    ax.set_ylim((0, None))\n",
    "    ax.set_xlabel(\"Component Number\", fontsize=\"xx-large\")\n",
    "    ax.set_ylabel(\"Variance Explained\", fontsize=\"xx-large\")\n",
    "    \n",
    "    # fig.suptitle(title, fontsize=\"xx-large\")\n",
    "    fig.tight_layout()\n",
    "    fig_root.mkdir(parents=True, exist_ok=True)\n",
    "    fig_name = fig_root / stem\n",
    "    fig.savefig(fig_name.with_suffix(\".pdf\"))\n",
    "    fig.savefig(fig_name.with_suffix(\".png\"))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac468a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clustering(rng, U, S, Vt, projections, n_cluster, n_sample, n_component, transform, init, dim, cache_key, labels_override = None):\n",
    "    idx = rng.choice(len(projections), size=n_sample, replace=False)\n",
    "    init_str = init\n",
    "\n",
    "    data = projections[idx, :n_component]\n",
    "    \n",
    "    if transform == \"unscale\":\n",
    "        data /= S[:data.shape[-1]]\n",
    "    elif transform == \"row_normalize\":\n",
    "        data /= S[:data.shape[-1]]\n",
    "        data /= np.linalg.norm(data, axis=-1, keepdims=True)\n",
    "\n",
    "    algo = KMeans(n_cluster, init=init, random_state=42, max_iter=1)\n",
    "    if labels_override is None:\n",
    "        algo.fit(data)\n",
    "        labels = algo.labels_ + 1\n",
    "    else:\n",
    "        labels = labels_override[idx]\n",
    "    \n",
    "    bounds = np.arange(n_cluster + 1) + 0.5\n",
    "    norm = BoundaryNorm(bounds, n_cluster)\n",
    "    \n",
    "    if dim == \"3d\":\n",
    "        fig, axes = plt.subplots(1, 2, subplot_kw=dict(projection='3d'))\n",
    "        cmap = ListedColormap(sns.color_palette('husl', n_cluster))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            ax.set_box_aspect(None, zoom=0.85)\n",
    "            first, second, third = 3*i, 3*i+1, 3*i+2\n",
    "            sc = ax.scatter(data[:, first], data[:, second], data[:, third],\n",
    "                            marker='.', cmap=cmap, norm=norm, c=labels, s=0.1, alpha=0.01)\n",
    "            # ax.set_xlabel(f\"PC{first+1}\", labelpad=10)\n",
    "            # ax.set_ylabel(f\"PC{second+1}\", labelpad=10)\n",
    "            # ax.set_zlabel(f\"PC{third+1}\", labelpad=15)\n",
    "            \n",
    "            ax.tick_params(axis='both', which='major', labelsize=4, pad=0)\n",
    "            # ax.tick_params(axis='both', which='minor', labelsize='small')\n",
    "            ax.grid(color='silver', linestyle='-')\n",
    "\n",
    "            x_bot, x_top = ax.get_xlim()\n",
    "            y_bot, y_top = ax.get_ylim()\n",
    "            z_bot, z_top = ax.get_zlim()\n",
    "            x_bot, x_top = x_bot - 0.12 * (x_top - x_bot), x_top + 0.12 * (x_top - x_bot)\n",
    "            y_bot, y_top = y_bot - 0.12 * (y_top - y_bot), y_top + 0.12 * (y_top - y_bot)\n",
    "            z_bot, z_top = z_bot - 0.12 * (z_top - z_bot), z_top + 0.12 * (z_top - z_bot)\n",
    "            ax.text(x_bot, y_bot, z_bot, f\"PC{first+1}\", \n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize='medium',\n",
    "                    fontweight='normal')\n",
    "            ax.text(x_top, y_top, z_bot, f\"PC{second+1}\", \n",
    "                    ha='center', va='center',\n",
    "                    fontsize='medium',\n",
    "                    fontweight='normal')\n",
    "            ax.text(x_bot, y_top, z_top, f\"PC{third+1}\", \n",
    "                    ha='center', va='center',\n",
    "                    fontsize='medium',\n",
    "                    fontweight='normal')\n",
    "            ax.set_title(f'PC{first+1} through PC{third+1}', fontsize='large')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 3)\n",
    "        cmap = ListedColormap(sns.color_palette('husl', n_cluster))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            first, second = 2*i, 2*i+1\n",
    "            sc = ax.scatter(data[:, first], data[:, second],\n",
    "                            marker='.', cmap=cmap, norm=norm, c=labels, s=0.1, alpha=0.01)\n",
    "            ax.set_xlabel(f\"PC{first+1}\")\n",
    "            ax.set_ylabel(f\"PC{second+1}\")\n",
    "            \n",
    "    # fig.subplots_adjust(top=0.85, bottom=0.2, wspace=0.1, hspace=0.25, right=0.95, left=0.05)\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "    \n",
    "    # Coordinates are [left, bottom, width, height] in figure fraction (0 to 1)\n",
    "    cax = fig.add_axes([0.15, 0.1, 0.7, 0.03])\n",
    "    cbar = plt.colorbar(sc, cax=cax, ticks=np.arange(n_cluster) + 1, orientation='horizontal')\n",
    "    cbar.set_alpha(1)\n",
    "    cbar.solids.set(alpha=1)\n",
    "    cbar.set_label(\"Cluster Membership\")\n",
    "    # fig.suptitle(\"$K$-Means Clustering\", fontsize=\"xx-large\", y=0.90)\n",
    "\n",
    "    fig_root.mkdir(parents=True, exist_ok=True)\n",
    "    fig_name = fig_root / f\"{cache_key}_{init_str}_{dim}_proj\"\n",
    "    plt.savefig(fig_name.with_suffix(\".pdf\"), bbox_inches='tight')\n",
    "    plt.savefig(fig_name.with_suffix(\".png\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return labels, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(bed, mask, env, covariates, n_component_rsvd, n_cluster, n_sample, n_component, cache_key, manifest, labels_override = None):\n",
    "    bed_op, frobenius_sq = preprocess(bed, mask, env, covariates, manifest)\n",
    "    U, S, Vt, projections = compute_rsvd(bed_op, frobenius_sq, n_component_rsvd, cache_key)\n",
    "    \n",
    "    rng = np.random.default_rng(42)\n",
    "    labels_kmeans, idx_kmeans = visualize_clustering(rng, U, S, Vt, projections, n_cluster, n_sample, n_component, None, \"k-means++\", \"3d\", cache_key, labels_override)\n",
    "    return labels_kmeans, idx_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14615e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.notna(fam_full.iid)\n",
    "env = covariates = np.ones(bed_full.shape[:-1])\n",
    "n_component_rsvd = 500\n",
    "n_cluster = 5\n",
    "n_sample = np.sum(mask)\n",
    "n_component = 10\n",
    "labels, idx = analyze(bed_full, mask, env, covariates, n_component_rsvd, n_cluster, n_sample, n_component, \"full\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda916ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_unhot_doh = pd.read_parquet('ohe_sdoh_data_unhot/split_unhot_doh.parquet')\n",
    "fam_full['person_id'] = fam_full.iid.astype(int)\n",
    "environments = fam_full.merge(split_unhot_doh, how='left', on='person_id', validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'qq40192410'\n",
    "mask = pd.notna(environments[env_name])\n",
    "env = environments.loc[mask, env_name].cat.codes.to_numpy()\n",
    "covariates = np.column_stack((np.ones(np.sum(mask)), env))\n",
    "n_component_rsvd = 500\n",
    "n_cluster = 5\n",
    "n_sample = np.sum(mask)\n",
    "n_component = 10\n",
    "labels, idx = analyze(bed_full, mask, env, covariates, n_component_rsvd, n_cluster, n_sample, n_component, env_name, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.notna(environments[env_name])\n",
    "env = np.ones_like(environments.loc[mask, env_name].cat.codes.to_numpy())\n",
    "covariates = np.ones(np.sum(mask))\n",
    "n_component_rsvd = 500\n",
    "n_cluster = 5\n",
    "n_sample = np.sum(mask)\n",
    "n_component = 10\n",
    "labels, idx = analyze(bed_full, mask, env, covariates, n_component_rsvd, n_cluster, n_sample, n_component, f\"{env_name}_ctrl\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111270c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.notna(environments[env_name])\n",
    "env = np.ones_like(environments.loc[mask, env_name].cat.codes.to_numpy())\n",
    "labels_override = environments.loc[mask, env_name].cat.codes.to_numpy()\n",
    "covariates = np.ones(np.sum(mask))\n",
    "n_component_rsvd = 500\n",
    "n_cluster = 5\n",
    "n_sample = np.sum(mask)\n",
    "n_component = 10\n",
    "labels, idx = analyze(bed_full, mask, env, covariates, n_component_rsvd, n_cluster, n_sample, n_component, f\"{env_name}_raw\", True, labels_override = labels_override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f784f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_full.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
